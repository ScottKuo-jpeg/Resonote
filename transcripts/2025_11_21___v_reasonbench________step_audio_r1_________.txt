🎼 听众朋友早上好，11月21日，hugging face每日AI论文速递带来15篇新鲜研究，视频生成推理，3D任意物体重建，手术视频分割，土耳其检索基准，干货已就位，马上开讲。😊.本期第一篇论文是V reason bench，面向视频生成模型的统一推理基准套件。研究者发现，像vivo3这类模型已能零样本推理，却缺少统一考卷。于是，他们搭建326组图文题，分结构化、空间模式、物理思维用pass at K给sra2可零等6款模型打分。结果sra2总分最高却无一模型全能拉长时间。反而可能添幻觉。论文提示，视频模型强在物理与过程推理，图像模型更稳符号题，未来需把画面好看与推理靠谱，真正对齐。本期节目聚焦第二篇论文step audioier一技术报告，它瞄准一个反常现象，语音模型越响越差。作者提出，modelality grounded reasoning distillation。把练式思考从文本蒸馏到真实声学特征，先冷启动再三轮自我蒸馏。让32B参数的Q问2.5学会用小于think大于标签边听边推理。结果新模型在big benchch audio拿到98.7%，实时版0.92秒延迟下仍保持96.1%准确率，首次证明多享对音频同样有效。.本期第三篇论文通过多模态基础模型扩展空间智能，作者没改网络，而是攒了850万条空间问答。为给que3VLin VL3的模型，结果在五项空间基准上刷新记录，同时，通用能力不掉分，数据越多，模型越会换位思考，还能零样本指挥机械臂一句话，好数据就能让AI长出真3D大脑。.本期节目第四篇论文，首帧是实现视频内容定制化的关键所在。研究团队发现，只要把多张参考图一次性塞进第一帧，再用50条视频做轻量Lara微调模型就能秒懂并生成高质量定制视频，无需改架构，也不用百万级数据，用户打分45分之5八成首选训练5小时搞定，为低成本视频创作，打开新思路。.本期第五篇论文视频及答案，使用联合GRRPO预测并生成下一视频事件。团队把下一事件预测，从文字升级成动态画面。ws模型先让视觉语言模型写出好拍的旁白，再让视频扩散模型把旁白变成连贯镜头。两阶段联合GRRPO强化学习，同步调优1万条教学与推理视频训练后，新指标入者提升近三成。人工评分达4点7分，证明专门部件协同比单打独斗更能让AI拍出的下一段视频既合理又好看。本期第六篇论文sam3D图像中任意物体的三维化，研究团队用1.2B参数几何模型加600M纹理模型，先合成预训练，再对齐真实图，靠300万无贴图网格和700万人工偏好，把单张生活照变立体物件。在SA3到基准，把F1从0.16拉到0.23，人凭5比1碾压对手，给AR机器人送上即拍及3D的新底座。本期节目第七篇论文中文标题，memo embodied跨距深基础模型技术报告。作者把自动驾驶和家用机器人放进同一套大模型里，用四阶段训练，先学通用视觉语言，再分别做驾驶和机器人任务，接着练思维链，最后用强化学习微调，结果在29项测试里刷出17项机器人12项驾驶的新纪录，跨域知识互相助攻。证明一个脑壳也能开好车和端好盘子。本期第八篇论文，中文标题边生成边思考，在视觉生成中交织文本推理。作者提出t个框架，让模型在画图过程中边画边想，随时用文字给下一区域写提示，画完再自我打分改细节。实验显示，领样本就能提升色彩绑定近20分，加上强化学习后复核指标全面领先，证明想的及时，图就更准更稳。.本期第九篇论文trkcobert土耳其信息检索中稠密与延迟交互模型的基准研究，团队把土耳其与特有的磁坠迷宫交给colbert的 token级交互，结果一兆参数的迷你模型就能追上6亿参数danceender平均检索精度只降不到三成，配合moover索引，查询延迟压到0.54毫秒，速度再提3倍，实验横跨财经。学术等5领域，lateate interaction全面领先，最高map拉升13.8%。结论形态越丰富，越要让模型看清每个词缀。本期节目第十篇论文nemeronelastic迈向高效多合一推理大语言模型，团队把6B9B12B3套模型套娃进同一套12B参数，训练一次就能按需抽壳，数学基准几乎不掉分，却省下300多倍算力，内存还砍半。简单说，以后一台24G显存的机器，就能跑三套推理模型。预算紧张也。能享受大模型红利。本期节目第11篇论文标题是自参考策略优化，面向视觉语言动作模型。作者把机器人学里最头疼的奖励稀疏问题变成自己给自己打分的游戏，先让模型随机试错，把成功的轨迹用世界模型压缩成里程碑，失败轨迹离这些里程碑越近，得分越高。结果，在libal基准里，200步就把成功率从49%拉到百分。99真实机械臂上也能一口气提升87%。简单说，它让机器人不再迷信人类示范，而是靠回顾自己高光时刻自学进阶。本期第12篇论文time viper，一种用于高效长视频理解的混合manbatransformer视觉语言模型。研究者把manba的线性复杂度与transformer的注意力拼成混血架构，再插入可学习的transv模块，在LLM内部按注意力得分，合并冗于视觉token，把万帧长片压进显存，结果在video mME等基准上精度不掉，反比纯transformer多生成。40%文本证明用先拼后丢的策略，1小时视频也能实时看懂。第13篇论文sam2S通过语翼长期跟踪实现手术视频中的任意分割，团队把通用sr升级成手术专精deavman模块向记忆抽屉长期计术器械Tel给每种工具贴语翼标签ARL自动忽略标注矛盾。新SASV基准汇集61000帧1600段连续mask训练后，sam2S一次点击就能全程追踪平均指。标飙升17分，仍跑68帧每秒，为实时手术导航提供更稳的眼睛。本期节目第14篇论文中文标题naax作为潜在颜色扩散的无缝纹理生成。作者干脆把纹理生成搬到3D空间，用几何感知颜色VAE把彩色点云压到280分之1，再用多控颜色DIT直接扩散出无缝贴图，五步就能出图，边界对的几乎零误差指标全面领先。他一次训练就能做材质，修细节，分布件，给3D内容创作开了条原生3D新路。本期第15篇论文partV基于部件分割的3D网格UV展开方法，它把先拆成有意义零件再展平的思路写进算法，用神经网络预测零件场，递归合并面片，兼固低扭区与语翼边界，结果图表数量骤减30倍，逢长缩短三成，对AI生成的noisy网格也能秒级搞定，让后续贴图压缩边辑都更干。性直观。🎼以上就是本期hugging face每日AI论文速递的全部内容，感谢你的收听，如果喜欢，欢迎评论、点赞、转发、订阅，小红书搜AI速递，找到我们，下期节目再见。😊该走。