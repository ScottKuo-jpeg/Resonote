🎼.听众朋友们周末好，欢迎来到hugging face每日AI论文速递周末特辑。2025年11月17日至23日，我们精选了5篇热度最高的论文inky5.0带来图像与视频生成的新基础模型。miuralthinkker把开源智能体推向新高度。还有用强化学习挑战物理奥赛简单加。😊让LLM性能跃升的汤吉模型，以及从感知到推理的视频理解框架，精彩内容马上开讲。本期的第一篇论文candinky5.0用于图像和视频生成的基础模型家族，目前在hugging face社区已经拿到171个点赞。这套模型把高分辨率长时长开源三个关键词，一次性打包，核心是一组cross attention diffusion transformer分三条产品线，6B参数的image light专做图片，2B的video light跑得快，主打文本或图片转短片。。19B的video pro则把分辨率再抬一档，能稳定输出10秒，24帧的连贯视频训练流程像精酿啤酒，先大规模原料筛选收集、清洗剧类图文数据再长时间发酵，预训练加自监督微调，最后调香，用强化学习，把细节美感和提示词对齐率一起拉高。为了速度，团队做了蒸馏，内存友好注意力和滑快分块。推理成本直接砍半，评测环节既跑自动指标feedc score也拉来真人打分，结果在开源阵营里全面领跑。更重要的是，代码和权重全部公开，相当于把顶级配方放进社区酒柜，谁都能接着调新口味。..这是本期节目的第二篇论文。中文标题是miuralthinker通过模型上下文与交互扩展，将开源研究智能体性能推向新边界。目前，在hugging face社区已经收获150个点赞。这篇工作的核心只有一个词交互扩展。过去我们习惯把开源研究智能体的性能瓶颈，归结为模型不够大，上下文不够长。而作者提出，真正被忽视。的维度是交互深度，让模型在任务里反复调用工具，不断获取外部反馈，把错误及时纠正，把推理链持续延长。为了验证这一思路，团队用8B30B72B3个规模的Q123分之5基座，把上下文拉到256K，并允许单次任务最多调用600次工具，形成一条监督微调偏号，优化在线强化学习的三段式训练流。水线工具箱里放的是Lux沙盒、pyython解释器，谷歌搜索、网页爬虫和文件读写模型自己决定何时用谁。上下文管理则采用最近5条优先的保留策略，既防止爆炸。.也保证关键信息不掉线，结果非常直观。在gea humanity s last exam brocom等7项公开基准上，mirow thinker把开源天花板整体抬升了一大截。gea81.9比之前最好成绩高出6.2个百分点。humanities's lost exam37.7 percent，甚至超过GP4欧的高配版本，更关键的是，这种交互扩展效应在8比。和30B模型上同样成立，强化学习后的轨迹长度是监督微调版的2到3倍，准确率再涨8到10分，说明交互深度确实像参数量一样可预测可优化。中文场景下，brocom拿到55.6%的新高，也证明交互能力可以跨语言迁移。作者最后把模型代码、工具链全部开源，等于给社区递了一把可复现的梯子。接下来，如果能再把调用效率、常链压缩和沙河安全做足，开源研究智能体与商业系统的差距，恐怕还会进一步缩小。本期节目的第三篇论文，中文标题是用强化学习攻克物理奥赛。这篇论文目前在huggingface社区已经收获了127个点赞。研究团队提出一个大胆目标，用纯强化学习，把开源大模型推到国际物理奥林匹克金牌水平，他们先精选5066道奥赛级题目，覆盖力学、电磁、热学等25个子领域，用三重模型。交叉验证答案，确保数据干净。接着把解题过程建模成马尔可夫决策过程，每生成一个token就算一步，只有最终答案，对或错，奖励是干脆的一或0为防训练崩掉。他们用了group sequence policy optimization和截段重要性采样，把30B和235B两种规模的queeen3模型按四阶段课程慢慢未提。生成窗口一路从48K拉到。80K token训练完模型直接参加2025年iphone235B版本，拿下21.2分，货真价实的全球第三金牌，30B版本也拿到18.5分，稳进银牌区。如果再加上团队设计的physicmin推理助手，让模型在胶卷前反复自检，重排答案，分数能再拔高到23.2，直接登顶世界第一，把GPT5和jamany25pro。都甩在身后，同样的系统在13场2024到25最新奥赛里包揽12金一银，连中国物理奥赛决赛都拿到227分，超过人类冠军28分。更妙的是，模型只刷过物理题，却在数学编码和通用stem测试上同步上涨。说明物理思维迁移性极强。作者总结高质量小数据配合RL就能把开源模型送进科学皇冠区。训练时扩规模与测试时上代理，两者互补。未来做实验设计、理论推导，甚至发现新物理都可能用得上。本期第四篇论文我们来聊聊汤吉模型，简单加权平均，即可让大语言模型性能越升。这篇研究目前在huggingface社区已经收获126个点赞，作者们盯上了一个现实痛点，再训练一次大模型，烧钱又烧卡，可开源社区里早就躺着一堆各具绝技的微调版li拉马3，于是他们干脆把拼积木思路搬到参数空间，挑出17小。工具调用十种语言、数学、超长上下文、三十六语翻译等弱相关子任务，各自找表现最好的单科冠军，再把他们的权重像熬汤一样，按比例倒进同一口锅。没有反向传播，没有新数据，只靠网格搜索非负权重，8B模型在BFCL上从72.4直接跳到76.570B更把天花板抬到80.7平均比单科状元。再涨二三个百分点。更妙的是，这锅杂烩不仅保留97%元技能，还额外补上了8.4%，大家原本都不会的题。相关性分析显示，原本各顾各的能力被拉成了更均衡的通财。作者提醒，以后打榜别只报总分，把系类分数公开出来，人人都能熬出自己的汤模型。.本期节目第五篇论文，中文标题叫video2R。从感知到推理的视频理解。这篇论文在hugging face社区已经拿到104个点赞。先一句话说清它的核心。过去让大模型看懂视频，常把看见了啥和想明白了啥，混成一锅粥，结果奖励信号一团模糊，学也学不对。作者干脆把感知和推理拆成两条流水线，各算各的分数在一起训练。😊嗯。取名叫video2R。具体怎么拆？第一步做监督微调，他们先让queen2.5VL72B生成16万条链式思考标注，再用cloud3.7当质检员，筛掉不靠谱的细节，确保每一步先看见，再推断都写的明明白白，第二步上强化学习新算法PAHGRPO给感知和推理分别打分，感知分看模型。有没有抓到关键帧推理分，看逻辑链能不能自洽，两条奖励曲线一起反向传播，误差不再乱背锅。实验结果很干脆。7个主流视频理解基准测一遍Vde2拿下6项。第一，平均准确率比基座模型直接抬高5.8个百分点，最吃劲的时空推理题，进步幅度拉到两位数。烧脑的是，哪怕把这套感知外挂直接安在别家模型身上，也能。再涨2分，说明好眼睛真能帮大脑。一句话总结，把看见和想明白分开算分。视频大模型终于知道哪儿学错，哪儿改错，推理之路不再黑箱。🎼以上就是本周5篇热榜论文的全部内容，感谢你的收听，如果喜欢请评论、点赞、转发、订阅小红书搜索AI速递，找到我们下周日huing face每日AI论文速递，再见。我是我会该走。😊